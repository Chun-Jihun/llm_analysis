import os
import streamlit as st
import pandas as pd
import plotly.express as px
from dotenv import load_dotenv
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.pydantic_v1 import BaseModel, Field, conlist
from typing import List, Dict

# --- 0. í™˜ê²½ ì„¤ì • ë° í˜ì´ì§€ êµ¬ì„± ---
st.set_page_config(
    page_title="ê²Œì„ ë¦¬ë·° ì¸ì‚¬ì´íŠ¸ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ®",
    layout="wide",
    initial_sidebar_state="expanded"
)

# .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ
load_dotenv()

# --- 1. LLM ë° Pydantic ëª¨ë¸ ì •ì˜ ---

# PM ë³´ê³ ì„œë¥¼ ìœ„í•œ êµ¬ì¡°í™”ëœ Pydantic ëª¨ë¸
class PrioritizedIssue(BaseModel):
    issue: str = Field(description="ìœ ì €ê°€ ê²ªëŠ” í•µì‹¬ ë¬¸ì œì  ë˜ëŠ” ë¹„íŒ ë‚´ìš©")
    reason: str = Field(description="ì´ ë¬¸ì œê°€ ì™œ ì¤‘ìš”í•˜ê³  ì‹œê¸‰í•œì§€ì— ëŒ€í•œ ë¶„ì„ (ì˜ˆ: ì‹ ê·œ ìœ ì € ì´íƒˆ ìœ ë°œ, í•µì‹¬ í”Œë ˆì´ ê²½í—˜ ì €í•´ ë“±)")
    priority: str = Field(description="ë¬¸ì œì˜ ì‹¬ê°ì„±ê³¼ ë¹ˆë„ë¥¼ ê³ ë ¤í•œ ìš°ì„ ìˆœìœ„ ì œì•ˆ (ì˜ˆ: 'ë§¤ìš° ë†’ìŒ', 'ë†’ìŒ', 'ë³´í†µ')")

class FeatureOpportunity(BaseModel):
    feature: str = Field(description="ìœ ì €ê°€ ì œì•ˆí•˜ê±°ë‚˜ ë¦¬ë·°ì—ì„œ ì•”ì‹œí•˜ëŠ” ìƒˆë¡œìš´ ê¸°ëŠ¥ ë˜ëŠ” ì½˜í…ì¸  ì•„ì´ë””ì–´")
    impact: str = Field(description="ì´ ê¸°ëŠ¥ì´ ì¶”ê°€ë˜ì—ˆì„ ë•Œ ì˜ˆìƒë˜ëŠ” ê¸ì •ì  íš¨ê³¼ (ì˜ˆ: ë¦¬í”Œë ˆì´ ê°€ì¹˜ ì¦ëŒ€, ìœ ì € ë§Œì¡±ë„ í–¥ìƒ ë“±)")

class PMReport(BaseModel):
    executive_summary: str = Field(description="í”„ë¡œì íŠ¸ ê´€ë¦¬ì ë° ì´í•´ê´€ê³„ìë¥¼ ìœ„í•œ í•µì‹¬ ìš”ì•½. í˜„ì¬ ìœ ì € ê°ì„± ìƒíƒœ, ê°€ì¥ ì¤‘ìš”í•œ ë°œê²¬, ê·¸ë¦¬ê³  ì¦‰ê°ì ì¸ ì¡°ì¹˜ê°€ í•„ìš”í•œ ì‚¬í•­ì„ ìš”ì•½í•©ë‹ˆë‹¤.")
    key_strengths: List[str] = Field(description="ê²Œì„ì˜ ëª…í™•í•œ ê°•ì  ë° ìœ ì €ë“¤ì´ ê³„ì† í”Œë ˆì´í•˜ëŠ” ì´ìœ . 'ìš°ë¦¬ ê²Œì„ì˜ USP(Unique Selling Point)'ì— í•´ë‹¹í•©ë‹ˆë‹¤.")
    prioritized_issues: List[PrioritizedIssue] = Field(description="ìš°ì„ ìˆœìœ„ê°€ ì§€ì •ëœ í•µì‹¬ ë¬¸ì œì  ëª©ë¡. ê°œë°œíŒ€ì´ ì¦‰ì‹œ ì°¸ê³ í•  ìˆ˜ ìˆë„ë¡ ì‹¤í–‰ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì œê³µí•©ë‹ˆë‹¤.")
    feature_opportunities: List[FeatureOpportunity] = Field(description="ìœ ì € í”¼ë“œë°± ê¸°ë°˜ì˜ ì‹ ê·œ ê¸°ëŠ¥ ë° ì„±ì¥ ê¸°íšŒ ëª©ë¡.")
    long_term_strategy: List[str] = Field(description="ì¥ê¸°ì ì¸ ê²Œì„ ë¡œë“œë§µ ë° ì „ëµì  ë°©í–¥ì„±ì— ëŒ€í•œ ì œì–¸.")

@st.cache_resource
def get_llm():
    """LLM ëª¨ë¸ì„ ìºì‹œí•˜ì—¬ ì¬ë¡œë”©ì„ ë°©ì§€í•©ë‹ˆë‹¤."""
    API_KEY = os.getenv("GEMINI_API_KEY")
    if not API_KEY:
        st.error("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()
    
    return ChatGoogleGenerativeAI(
        google_api_key=API_KEY,
        model='gemini-1.5-flash',
        temperature=0.7,
    )

def run_llm_analysis(reviews_text: str):
    """Geminië¥¼ ì‚¬ìš©í•˜ì—¬ PM ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    llm = get_llm()
    parser = JsonOutputParser(pydantic_object=PMReport)

    prompt = ChatPromptTemplate.from_messages([
        ("system", "ë‹¹ì‹ ì€ ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •ì„ ë‚´ë¦¬ëŠ” ìˆ™ë ¨ëœ ê²Œì„ í”„ë¡œì íŠ¸ ë§¤ë‹ˆì €(PM)ì…ë‹ˆë‹¤. ì œê³µëœ ìœ ì € ë¦¬ë·°ë¥¼ ì‹¬ì¸µ ë¶„ì„í•˜ì—¬, ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œì™€ ì—°ê³„ëœ ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ë‹´ì€ ë³´ê³ ì„œë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤. ë‹¨ìˆœíˆ ë¦¬ë·°ë¥¼ ìš”ì•½í•˜ëŠ” ê²ƒì„ ë„˜ì–´, ë¬¸ì œì˜ ìš°ì„ ìˆœìœ„ë¥¼ ì •í•˜ê³ , ê¸°íšŒë¥¼ í¬ì°©í•˜ë©°, ì¥ê¸°ì ì¸ ì „ëµì„ ì œì‹œí•´ì£¼ì„¸ìš”."),
        ("human", "ì•„ë˜ëŠ” ìš°ë¦¬ ê²Œì„ì— ëŒ€í•œ ìœ ì € ë¦¬ë·° ë°ì´í„°ì…ë‹ˆë‹¤. ì´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•œ PM ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.\n\n--- ë¦¬ë·° ë‚´ìš© ---\n{reviews_text}\n\n--- ë¶„ì„ ë³´ê³ ì„œ ---"),
        ("ai", "{format_instructions}")
    ])
    
    chain = prompt | llm | parser
    
    try:
        return chain.invoke({
            "reviews_text": reviews_text,
            "format_instructions": parser.get_format_instructions()
        })
    except Exception as e:
        st.error(f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None

# --- 2. ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ ---

@st.cache_data
def load_data(file_path):
    """CSV ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ê¸°ë³¸ ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. (ìºì‹œ ì‚¬ìš©)"""
    df = pd.read_csv(file_path)
    df['timestamp_created'] = pd.to_datetime(df['timestamp_created'], unit='s')
    df.rename(columns={'review_text': 'ë¦¬ë·° ë‚´ìš©', 'voted_up': 'ê¸ì • ë¦¬ë·°'}, inplace=True)
    return df

df_original = load_data('steam_reviews_3430470_korean_limit600_unique.csv')

# --- 3. ì‚¬ì´ë“œë°” í•„í„° ---

st.sidebar.header("ğŸ“Š ëŒ€ì‹œë³´ë“œ í•„í„°")

playtime_range = st.sidebar.slider(
    "í”Œë ˆì´ ì‹œê°„(ì‹œê°„) í•„í„°",
    min_value=0,
    max_value=int(df_original['playtime_forever_hours'].max()),
    value=(0, int(df_original['playtime_forever_hours'].quantile(0.95))) # ê¸°ë³¸ê°’: ìƒìœ„ 5% ì´ìƒì¹˜ ì œì™¸
)

review_type_map = {'ëª¨ë‘': None, 'ê¸ì •ì  ë¦¬ë·° ğŸ‘': True, 'ë¶€ì •ì  ë¦¬ë·° ğŸ‘': False}
selected_review_type = st.sidebar.selectbox(
    "ë¦¬ë·° ìœ í˜• í•„í„°",
    options=list(review_type_map.keys())
)

# í•„í„° ì ìš©
df_filtered = df_original[
    (df_original['playtime_forever_hours'] >= playtime_range[0]) &
    (df_original['playtime_forever_hours'] <= playtime_range[1])
]

if review_type_map[selected_review_type] is not None:
    df_filtered = df_filtered[df_filtered['ê¸ì • ë¦¬ë·°'] == review_type_map[selected_review_type]]

# --- 4. ëŒ€ì‹œë³´ë“œ UI êµ¬ì„± ---

st.title("ğŸ® ê²Œì„ ë¦¬ë·° ì¸ì‚¬ì´íŠ¸ ëŒ€ì‹œë³´ë“œ for PM")
st.markdown(f"**ë¶„ì„ ê¸°ê°„:** `{df_original['timestamp_created'].min().date()}` ~ `{df_original['timestamp_created'].max().date()}` | **ì´ ë¦¬ë·°:** `{len(df_original)}`ê°œ | **í•„í„°ëœ ë¦¬ë·°:** `{len(df_filtered)}`ê°œ")


# íƒ­ êµ¬ì„±
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸ“ˆ **KPI ìš”ì•½**",
    "ğŸ’¬ **AI ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„**",
    "â° **ì‹œê³„ì—´ ë¶„ì„**",
    "ğŸ‘¥ **ë¦¬ë·°ì–´ í”„ë¡œí•„**",
    "ğŸ” **ì›ë³¸ ë°ì´í„° íƒìƒ‰**"
])


with tab1:
    st.header("ğŸ“ˆ í•µì‹¬ ì„±ê³¼ ì§€í‘œ (KPI) ìš”ì•½")
    
    col1, col2, col3 = st.columns(3)
    
    positive_ratio = (df_filtered['ê¸ì • ë¦¬ë·°'].sum() / len(df_filtered) * 100) if len(df_filtered) > 0 else 0
    col1.metric("ê¸ì • ë¦¬ë·° ë¹„ìœ¨", f"{positive_ratio:.1f}%")
    
    avg_playtime = df_filtered['playtime_forever_hours'].mean()
    col2.metric("í‰ê·  í”Œë ˆì´ ì‹œê°„ (ë¦¬ë·° ì‘ì„± ì‹œ)", f"{avg_playtime:.1f} ì‹œê°„")

    avg_votes_up = df_filtered['votes_up'].mean()
    col3.metric("ë¦¬ë·°ë‹¹ í‰ê·  'ë„ì›€ë¨' íˆ¬í‘œ", f"{avg_votes_up:.1f} ê°œ")

    # ê¸ì •/ë¶€ì • ë¦¬ë·° ë¹„ìœ¨ íŒŒì´ ì°¨íŠ¸
    st.subheader("ë¦¬ë·° ìœ í˜• ë¶„í¬")
    if not df_filtered.empty:
        fig_pie = px.pie(
            df_filtered, names='ê¸ì • ë¦¬ë·°',
            title='í•„í„°ëœ ë¦¬ë·°ì˜ ê¸ì •/ë¶€ì • ë¹„ìœ¨',
            hole=0.3,
            color_discrete_map={True: 'royalblue', False: 'darkorange'},
            labels={'ê¸ì • ë¦¬ë·°': 'ë¦¬ë·° ìœ í˜•'}
        )
        fig_pie.update_traces(textinfo='percent+label', marker=dict(line=dict(color='#000000', width=2)))
        st.plotly_chart(fig_pie, use_container_width=True)
    else:
        st.warning("ì„ íƒëœ í•„í„°ì— í•´ë‹¹í•˜ëŠ” ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")

with tab2:
    st.header("ğŸ’¬ AI ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„ (Gemini)")
    st.markdown("í•„í„°ë§ëœ ë¦¬ë·° í…ìŠ¤íŠ¸ë¥¼ AI ëª¨ë¸ì— ì „ë‹¬í•˜ì—¬ PM ê´€ì ì˜ ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤.")

    if st.button("ğŸ¤– í•„í„°ëœ ë¦¬ë·°ë¡œ AI ë¶„ì„ ì‹¤í–‰í•˜ê¸°"):
        if not df_filtered.empty:
            reviews_for_analysis = "\n".join(df_filtered['ë¦¬ë·° ë‚´ìš©'].dropna().head(100)) # í† í° ì œí•œ ê³ ë ¤, 100ê°œ ìƒ˜í”Œ
            with st.spinner("Geminiê°€ ë¦¬ë·°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”..."):
                report = run_llm_analysis(reviews_for_analysis)
                
                if report:
                    st.subheader("Executive Summary (ê²½ì˜ì§„ ìš”ì•½)")
                    st.info(report['executive_summary'])

                    st.subheader("âœ… ê°•ì  (Our Strengths)")
                    for strength in report['key_strengths']:
                        st.success(f"**- {strength}**")
                    
                    st.subheader("ğŸ”¥ ê°œì„  ìš°ì„ ìˆœìœ„ (Issues to Prioritize)")
                    for issue in report['prioritized_issues']:
                        with st.expander(f"**{issue['priority']}**: {issue['issue']}"):
                            st.write(f"**ë¶„ì„:** {issue['reason']}")
                    
                    st.subheader("ğŸš€ ì‹ ê·œ ê¸°íšŒ (Feature Opportunities)")
                    for opp in report['feature_opportunities']:
                        with st.container(border=True):
                            st.markdown(f"**ê¸°ëŠ¥/ì½˜í…ì¸ :** {opp['feature']}")
                            st.markdown(f"**ê¸°ëŒ€ íš¨ê³¼:** {opp['impact']}")
                            
                    st.subheader("ğŸ—ºï¸ ì¥ê¸° ì „ëµ ì œì•ˆ (Long-term Strategy)")
                    for strategy in report['long_term_strategy']:
                        st.markdown(f"- {strategy}")
                else:
                    st.error("ë¶„ì„ ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            st.warning("ë¶„ì„í•  ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ì£¼ì„¸ìš”.")

with tab3:
    st.header("â° ë¦¬ë·° ê°ì„± ì‹œê³„ì—´ ë¶„ì„")
    st.markdown("ì‹œê°„ì˜ íë¦„ì— ë”°ë¥¸ ê¸ì •/ë¶€ì • ë¦¬ë·°ì˜ ì¶”ì„¸ë¥¼ í™•ì¸í•˜ì—¬ íŠ¹ì • ì—…ë°ì´íŠ¸ë‚˜ ì´ë²¤íŠ¸ì˜ ì˜í–¥ì„ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    # ì£¼(Week) ë‹¨ìœ„ë¡œ ë°ì´í„° ë¦¬ìƒ˜í”Œë§
    df_resampled = df_filtered.set_index('timestamp_created').resample('W').agg(
        positive_reviews=('ê¸ì • ë¦¬ë·°', lambda x: (x == True).sum()),
        negative_reviews=('ê¸ì • ë¦¬ë·°', lambda x: (x == False).sum())
    ).reset_index()

    fig_timeline = px.bar(
        df_resampled,
        x='timestamp_created',
        y=['positive_reviews', 'negative_reviews'],
        title='ì£¼ë³„ ê¸ì •/ë¶€ì • ë¦¬ë·° ìˆ˜ ì¶”ì´',
        labels={'timestamp_created': 'ë‚ ì§œ', 'value': 'ë¦¬ë·° ìˆ˜', 'variable': 'ë¦¬ë·° ìœ í˜•'},
        color_discrete_map={'positive_reviews': 'royalblue', 'negative_reviews': 'darkorange'}
    )
    st.plotly_chart(fig_timeline, use_container_width=True)

with tab4:
    st.header("ğŸ‘¥ ë¦¬ë·°ì–´ í”„ë¡œí•„ ë¶„ì„")
    st.markdown("ì–´ë–¤ ì„±í–¥ì˜ ìœ ì €ë“¤ì´ ìš°ë¦¬ ê²Œì„ì— ëŒ€í•´ ë¦¬ë·°ë¥¼ ë‚¨ê¸°ëŠ”ì§€ íŒŒì•…í•˜ì—¬ í•µì‹¬ íƒ€ê²Ÿ ê³ ê°ì„ ì´í•´í•©ë‹ˆë‹¤.")

    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ìœ ì €ì˜ ê²Œì„ ë³´ìœ  ìˆ˜ ë¶„í¬")
        fig_games_owned = px.histogram(
            df_filtered, x='num_games_owned', nbins=50,
            title="ë¦¬ë·°ì–´ì˜ ìŠ¤íŒ€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê·œëª¨",
            labels={'num_games_owned': 'ë³´ìœ  ê²Œì„ ìˆ˜'}
        )
        st.plotly_chart(fig_games_owned, use_container_width=True)

    with col2:
        st.subheader("ìœ ì €ì˜ ë¦¬ë·° ì‘ì„± ìˆ˜ ë¶„í¬")
        fig_num_reviews = px.histogram(
            df_filtered, x='num_reviews_by_author', nbins=50,
            title="ë¦¬ë·°ì–´ì˜ ìŠ¤íŒ€ ë¦¬ë·° í™œë™ì„±",
            labels={'num_reviews_by_author': 'ì‘ì„±í•œ ë¦¬ë·° ìˆ˜'}
        )
        st.plotly_chart(fig_num_reviews, use_container_width=True)
        
    st.markdown("---")
    st.subheader("êµ¬ë§¤ vs ë¬´ë£Œ ì œê³µ ìœ ì € ë¹„êµ")
    purchase_comparison = df_filtered.groupby('steam_purchase')['ê¸ì • ë¦¬ë·°'].value_counts(normalize=True).unstack().fillna(0) * 100
    st.dataframe(purchase_comparison.style.format("{:.1f}%"))
    st.caption("`True`ëŠ” ìŠ¤íŒ€ ìƒì  êµ¬ë§¤, `False`ëŠ” í‚¤ ë“±ë¡ ë“± ë‹¤ë¥¸ ê²½ë¡œë¡œ íšë“í•œ ê²½ìš°ì…ë‹ˆë‹¤.")


with tab5:
    st.header("ğŸ” ì›ë³¸ ë°ì´í„° íƒìƒ‰")
    st.markdown("í•„í„°ë§ëœ ë¦¬ë·° ì›ë³¸ ë°ì´í„°ë¥¼ ì§ì ‘ í™•ì¸í•˜ê³  ì •ë ¬í•˜ê±°ë‚˜ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    st.dataframe(df_filtered[[
        'ë¦¬ë·° ë‚´ìš©', 'ê¸ì • ë¦¬ë·°', 'playtime_forever_hours', 'votes_up', 'timestamp_created', 'steam_purchase'
    ]], use_container_width=True, height=500)